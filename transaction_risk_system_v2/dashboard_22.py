# dashboard_22.py
# ============================================================
# MODULE B / 2.2 ‚Äî –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã
# Streamlit dashboard: –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π + —Ñ–∏–ª—å—Ç—Ä—ã + –≥—Ä–∞—Ñ–∏–∫–∏
# ============================================================

import os
import sqlite3
import pandas as pd
import numpy as np
import streamlit as st

# (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –∞–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
try:
    from streamlit_autorefresh import st_autorefresh
    AUTORF_AVAILABLE = True
except Exception:
    AUTORF_AVAILABLE = False


# ============================================================
# 0) –ù–ê–°–¢–†–û–ô–ö–ò (–ú–ï–ù–Ø–¢–¨ –ù–ê –°–û–†–ï–í–ù–û–í–ê–ù–ò–ò)
# ============================================================

DB_PATH = "db/app.db"  # <-- –ú–ï–ù–Ø–¢–¨: –ø—É—Ç—å –∫ –±–∞–∑–µ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–æ–≥–æ, –≥–¥–µ –∑–∞–ø—É—Å–∫–∞–µ—à—å `streamlit run`)

# –ù–∞–∑–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü –≤ –ë–î
EVENTS_TABLE = "transactions"   # <-- –ú–ï–ù–Ø–¢–¨
MCC_TABLE = "mcc_codes"         # <-- –ú–ï–ù–Ø–¢–¨
TYPES_TABLE = "tr_types"        # <-- –ú–ï–ù–Ø–¢–¨
GENDER_TABLE = "gender_train"   # <-- –ú–ï–ù–Ø–¢–¨

# –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
ID_COL = "customer_id"          # <-- –ú–ï–ù–Ø–¢–¨
DT_COL = "tr_datetime"          # <-- –ú–ï–ù–Ø–¢–¨
MCC_COL = "mcc_code"            # <-- –ú–ï–ù–Ø–¢–¨
TYPE_COL = "tr_type"            # <-- –ú–ï–ù–Ø–¢–¨
AMOUNT_COL = "amount"           # <-- –ú–ï–ù–Ø–¢–¨
TERM_COL = "term_id"            # <-- –ú–ï–ù–Ø–¢–¨/–û–¢–ö–õ–Æ–ß–ò–¢–¨ (–µ—Å–ª–∏ –Ω–µ—Ç)

# –í —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞—Ö
MCC_DESC_COL = "mcc_description"    # <-- –ú–ï–ù–Ø–¢–¨
TYPE_DESC_COL = "tr_description"    # <-- –ú–ï–ù–Ø–¢–¨
GENDER_COL = "gender"               # <-- –ú–ï–ù–Ø–¢–¨

# –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
MAX_ROWS = 2_000_000  # <-- –ú–ï–ù–Ø–¢–¨: 200k..5M (–∏–ª–∏ None)

# –ö–æ–¥ –¥–æ—Å—Ç—É–ø–∞ –¥–ª—è Analyst (–∏–º–∏—Ç–∞—Ü–∏—è —É—Ä–æ–≤–Ω–µ–π –¥–æ—Å—Ç—É–ø–∞)
ACCESS_CODE = "1234"  # <-- –ú–ï–ù–Ø–¢–¨


# ============================================================
# 1) UI / PAGE
# ============================================================

st.set_page_config(page_title="Transaction Analytics 2.2", layout="wide")
st.title("üìä Transaction Analytics Dashboard (Module B / 2.2)")
st.caption("–§–∏–ª—å—Ç—Ä—ã: MCC / –ø–æ–ª / –≤—Ä–µ–º—è —Å—É—Ç–æ–∫ / —Ç–∏–ø –æ–ø–µ—Ä–∞—Ü–∏–∏. –ì—Ä–∞—Ñ–∏–∫–∏ –∏ —Ç–∞–±–ª–∏—Ü—ã –ø–æ –∑–∞–¥–∞–Ω–∏—é 2.2.")




# ============================================================
# 2) –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================================

@st.cache_resource
def get_conn(db_path: str):
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"DB file not found: {db_path}")
    return sqlite3.connect(db_path, check_same_thread=False)

def safe_read_sql(con, sql: str) -> pd.DataFrame | None:
    try:
        return pd.read_sql(sql, con)
    except Exception:
        return None

def parse_dt_to_hour(df: pd.DataFrame, dt_col: str) -> pd.DataFrame:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ –ø–æ–ª—É—á–∞–µ–º hour –∏–∑ dt_col.
    –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤:
      - "0 10:23:26"
      - "YYYY-MM-DD HH:MM:SS"
      - —á—Ç–æ-—Ç–æ –ø–æ—Ö–æ–∂–µ–µ (–ø—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å —á–∞—Å)
    """
    if dt_col not in df.columns:
        df["hour"] = np.nan
        return df

    s = df[dt_col].astype(str)

    # –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–µ–ª ‚Äî —á–∞—Å—Ç–æ —Å–ø—Ä–∞–≤–∞ –≤—Ä–µ–º—è
    parts = s.str.split(" ", n=1, expand=True)
    t = parts[1] if parts.shape[1] == 2 else s

    # —á–∞—Å = –¥–æ –¥–≤–æ–µ—Ç–æ—á–∏—è
    hour = t.str.split(":", n=1, expand=True)[0]
    df["hour"] = pd.to_numeric(hour, errors="coerce")
    return df

def hour_to_tod(hour: pd.Series) -> pd.Series:
    """
    time-of-day:
      night: 0-5
      morning: 6-11
      day: 12-17
      evening: 18-23
    """
    h = hour.fillna(-1).astype(int)
    return pd.Series(
        np.where((h >= 0) & (h <= 5), "night",
        np.where((h >= 6) & (h <= 11), "morning",
        np.where((h >= 12) & (h <= 17), "day",
        np.where((h >= 18) & (h <= 23), "evening", "unknown")))),
        index=hour.index
    )


# ============================================================
# 3) –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ò–ó –ë–î
# ============================================================

with st.spinner("‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î –∏ –≥–æ—Ç–æ–≤–ª—é –¥–∞—à–±–æ—Ä–¥‚Ä¶"):
    con = get_conn(DB_PATH)

    limit_sql = f"LIMIT {MAX_ROWS}" if isinstance(MAX_ROWS, int) and MAX_ROWS > 0 else ""

    sql_events = f"""
    SELECT
      {ID_COL} AS customer_id,
      {DT_COL} AS tr_datetime,
      {MCC_COL} AS mcc_code,
      {TYPE_COL} AS tr_type,
      {AMOUNT_COL} AS amount,
      {TERM_COL} AS term_id
    FROM {EVENTS_TABLE}
    {limit_sql}
    """
    df_e = safe_read_sql(con, sql_events)
    if df_e is None or df_e.empty:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å events –∏–∑ –ë–î. –ü—Ä–æ–≤–µ—Ä—å DB_PATH, EVENTS_TABLE –∏ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫.")
        st.stop()

    # —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ (–º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
    df_m = safe_read_sql(con, f"SELECT {MCC_COL} AS mcc_code, {MCC_DESC_COL} AS mcc_description FROM {MCC_TABLE}")
    df_t = safe_read_sql(con, f"SELECT {TYPE_COL} AS tr_type, {TYPE_DESC_COL} AS tr_description FROM {TYPES_TABLE}")
    df_g_raw = safe_read_sql(con, f"SELECT {ID_COL} AS customer_id, {GENDER_COL} AS gender FROM {GENDER_TABLE}")

    # join MCC
    if isinstance(df_m, pd.DataFrame) and not df_m.empty and {"mcc_code", "mcc_description"}.issubset(df_m.columns):
        df_e = df_e.merge(df_m.drop_duplicates("mcc_code"), on="mcc_code", how="left")
    else:
        df_e["mcc_description"] = None

    # join Types
    if isinstance(df_t, pd.DataFrame) and not df_t.empty and {"tr_type", "tr_description"}.issubset(df_t.columns):
        df_e = df_e.merge(df_t.drop_duplicates("tr_type"), on="tr_type", how="left")
    else:
        df_e["tr_description"] = None

    # join Gender (Pylance-safe)
    has_gender = isinstance(df_g_raw, pd.DataFrame) and (not df_g_raw.empty) and {"customer_id", "gender"}.issubset(df_g_raw.columns)
    if has_gender:
        df_g = df_g_raw[["customer_id", "gender"]].drop_duplicates("customer_id")
        df_e = df_e.merge(df_g, on="customer_id", how="left")
    else:
        df_e["gender"] = np.nan

    # –±–∞–∑–æ–≤–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    df_e = parse_dt_to_hour(df_e, "tr_datetime")
    df_e["tod"] = hour_to_tod(df_e["hour"])

    df_e["flow"] = np.where(df_e["amount"] < 0, "spend", np.where(df_e["amount"] > 0, "income", "zero"))
    df_e["abs_amount"] = df_e["amount"].abs()

    st.caption(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π: {len(df_e):,} | –∫–ª–∏–µ–Ω—Ç–æ–≤: {df_e['customer_id'].nunique():,}")




# ============================================================
# 4) SIDEBAR: –†–û–õ–ò + –§–ò–õ–¨–¢–†–´ (–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –±–ª–æ–∫!)
# ============================================================

st.sidebar.header("‚öôÔ∏è –†–æ–ª—å –∏ —Ñ–∏–ª—å—Ç—Ä—ã 2.2")

# --- –†–û–õ–ò ---
if "role_22" not in st.session_state:
    st.session_state.role_22 = "Viewer"

role_choice = st.sidebar.selectbox(
    "–†–æ–ª—å",
    ["Viewer", "Analyst"],
    index=0 if st.session_state.role_22 == "Viewer" else 1,
    key="role_sel_22"   # ‚úÖ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π key
)

role = "Viewer"
is_analyst = False

if role_choice == "Viewer":
    role = "Viewer"
    is_analyst = False
    st.session_state.role_22 = "Viewer"
    st.sidebar.info("–†–æ–ª—å: Viewer")
else:
    code = st.sidebar.text_input(
        "–ö–æ–¥ –¥–æ—Å—Ç—É–ø–∞ (Analyst)",
        type="password",
        key="pwd_22"      # ‚úÖ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π key
    )

    # –ø–æ–∫–∞ –∫–æ–¥ –Ω–µ –≤–≤–µ–¥—ë–Ω ‚Äî –Ω–µ –≤–∞–ª–∏–º –æ—à–∏–±–∫–æ–π, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ—Å–∏–º –≤–≤–µ—Å—Ç–∏
    if code.strip() == "":
        st.sidebar.info("–í–≤–µ–¥–∏—Ç–µ –∫–æ–¥, —á—Ç–æ–±—ã –≤–∫–ª—é—á–∏—Ç—å Analyst.")
        st.session_state.role_22 = "Viewer"
        st.stop()

    if code.strip() == str(ACCESS_CODE).strip():
        role = "Analyst"
        is_analyst = True
        st.session_state.role_22 = "Analyst"
        st.sidebar.success("–î–æ—Å—Ç—É–ø Analyst ‚úÖ")
    else:
        st.sidebar.error("–ù–µ–≤–µ—Ä–Ω—ã–π –∫–æ–¥. –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ Viewer.")
        st.session_state.role_22 = "Viewer"
        st.stop()

st.sidebar.caption(f"–¢–µ–∫—É—â–∞—è —Ä–æ–ª—å: {role}")

# --- –ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (—Ç–æ–ª—å–∫–æ Analyst) ---
auto_refresh = st.sidebar.checkbox(
    "–ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫",
    value=False,
    disabled=not is_analyst,
    key="autorefresh_chk_22"     # ‚úÖ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π key
)

if auto_refresh:
    if AUTORF_AVAILABLE:
        st_autorefresh(interval=30_000, key="autorefresh_tick_22")
    else:
        st.sidebar.warning("streamlit-autorefresh –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

st.sidebar.divider()

# --- –§–ò–õ–¨–¢–†–´ ---
all_mcc = sorted(df_e["mcc_code"].dropna().unique().tolist())
mcc_selected = st.sidebar.multiselect(
    "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ MCC",
    all_mcc,
    default=[],
    key="mcc_ms_22"              # ‚úÖ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π key
)

tod_all = ["night", "morning", "day", "evening", "unknown"]
tod_selected = st.sidebar.multiselect(
    "–í—Ä–µ–º—è —Å—É—Ç–æ–∫",
    tod_all,
    default=["night", "morning", "day", "evening"],
    key="tod_ms_22"              # ‚úÖ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π key
)

gender_selected = None
if has_gender and df_e["gender"].notna().any():
    gender_vals = sorted(df_e["gender"].dropna().unique().tolist())
    gender_selected = st.sidebar.multiselect(
        "–ü–æ–ª (gender)",
        gender_vals,
        default=gender_vals,
        key="gender_ms_22"        # ‚úÖ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π key
    )

flow_selected = st.sidebar.multiselect(
    "–¢–∏–ø –ø–æ—Ç–æ–∫–∞",
    ["spend", "income", "zero"],
    default=["spend"],
    key="flow_ms_22"             # ‚úÖ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π key
)

# --- –ü–†–ò–ú–ï–ù–Ø–ï–ú –§–ò–õ–¨–¢–†–´ -> df_f (—á—Ç–æ–±—ã –ø–æ—Ç–æ–º –Ω–µ –±—ã–ª–æ NameError) ---
df_f = df_e.copy()

if mcc_selected:
    df_f = df_f[df_f["mcc_code"].isin(mcc_selected)]

if tod_selected:
    df_f = df_f[df_f["tod"].isin(tod_selected)]

if gender_selected is not None:
    df_f = df_f[df_f["gender"].isin(gender_selected)]

if flow_selected:
    df_f = df_f[df_f["flow"].isin(flow_selected)]

st.sidebar.caption(f"–°—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞: {len(df_f):,}")

# ============================================================
# 5) –ö–õ–Æ–ß–ï–í–´–ï –ú–ï–¢–†–ò–ö–ò
# ============================================================

if 'df_f' not in globals() or df_f.empty:
    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø—Ä–æ–≤–µ—Ä—å —Ñ–∏–ª—å—Ç—Ä—ã)")
else:
    tx_cnt = len(df_f)
    clients_cnt = df_f["customer_id"].nunique()

    avg_check = df_f["abs_amount"].mean()
    avg_check = 0.0 if pd.isna(avg_check) else avg_check

    spend_sum = df_f.loc[df_f["flow"] == "spend", "abs_amount"].sum()
    income_sum = df_f.loc[df_f["flow"] == "income", "amount"].sum()

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏", f"{tx_cnt:,}")
    c2.metric("–ö–ª–∏–µ–Ω—Ç—ã", f"{clients_cnt:,}")
    c3.metric("–°—Ä–µ–¥–Ω–∏–π —á–µ–∫ (abs)", f"{avg_check:.2f}")
    c4.metric("–°—É–º–º–∞ —Ä–∞—Å—Ö–æ–¥–æ–≤ (abs)", f"{spend_sum:.2f}")
    c5.metric("–°—É–º–º–∞ –¥–æ—Ö–æ–¥–æ–≤", f"{income_sum:.2f}")


# ============================================================
# 6) –ê–ù–ê–õ–ò–¢–ò–ö–ê 2.2
# ============================================================

if df_f.empty:
    st.stop()

st.markdown("## 2.2 –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è")

left, right = st.columns([1, 1])

# A) –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –≤ —Ä–∞–∑–Ω–æ–µ –≤—Ä–µ–º—è —Å—É—Ç–æ–∫
with left:
    st.subheader("üìå –°—Ä–µ–¥–Ω–∏–π —á–µ–∫ –ø–æ MCC –∏ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫")

    tmp = df_f.copy()
    agg = (
        tmp.groupby(["tod", "mcc_code"], dropna=False)
           .agg(
                avg_amount=("abs_amount", "mean"),
                cnt=("abs_amount", "size"),
                sum_amount=("abs_amount", "sum"),
            )
           .reset_index()
    )

    if "mcc_description" in tmp.columns:
        agg = agg.merge(tmp[["mcc_code", "mcc_description"]].drop_duplicates(), on="mcc_code", how="left")

    st.dataframe(agg.sort_values("sum_amount", ascending=False).head(20), use_container_width=True)

# B) –ì—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å—É–º–º—ã –æ–ø–µ—Ä–∞—Ü–∏–π –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫ (–ø–æ —á–∞—Å–∞–º)
with right:
    st.subheader("üìà –°—É–º–º–∞ –æ–ø–µ—Ä–∞—Ü–∏–π –ø–æ —á–∞—Å–∞–º")

    tmp = df_f.copy()
    tmp["_spend_abs"] = np.where(tmp["flow"] == "spend", tmp["abs_amount"], 0.0)
    tmp["_income_amt"] = np.where(tmp["flow"] == "income", tmp["amount"], 0.0)

    by_hour = (
        tmp.groupby("hour", dropna=False)
           .agg(
                cnt=("amount", "size"),
                spend_sum=("_spend_abs", "sum"),
                income_sum=("_income_amt", "sum"),
            )
           .reset_index()
           .sort_values("hour")
    )

    st.line_chart(by_hour.set_index("hour")[["cnt", "spend_sum", "income_sum"]], use_container_width=True)
    st.caption("–õ–∏–Ω–∏–∏: cnt (–∫–æ–ª-–≤–æ), spend_sum (—Ä–∞—Å—Ö–æ–¥—ã), income_sum (–¥–æ—Ö–æ–¥—ã).")

# C) –í–ª–∏—è–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤ –Ω–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç–æ–≤
st.subheader("üî• –í–ª–∏—è–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (MCC) –Ω–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç–æ–≤")

df_spend = df_f[df_f["flow"] == "spend"].copy()
act = (
    df_spend.groupby("mcc_code")
            .agg(
                tx_cnt=("amount", "size"),
                clients=("customer_id", "nunique"),
                spend_sum=("abs_amount", "sum"),
                avg_check=("abs_amount", "mean"),
            )
            .reset_index()
            .sort_values("spend_sum", ascending=False)
)

if "mcc_description" in df_spend.columns:
    act = act.merge(df_spend[["mcc_code", "mcc_description"]].drop_duplicates(), on="mcc_code", how="left")

st.dataframe(act.head(30), use_container_width=True)
st.bar_chart(act.head(30).set_index("mcc_code")["spend_sum"], use_container_width=True)

# D) –í–∑–∞–∏–º–æ—Å–≤—è–∑—å —Ç–∏–ø–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (—Ç—Ä–∞—Ç–∞/–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ) —Å —á–∞—Å—Ç–æ—Ç–æ–π –æ–ø–µ—Ä–∞—Ü–∏–π
st.subheader("üîÅ –ß–∞—Å—Ç–æ—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–π: —Ç—Ä–∞—Ç—ã vs –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è")

freq = (
    df_f.groupby("flow")
        .agg(
            tx_cnt=("amount", "size"),
            clients=("customer_id", "nunique"),
            avg_abs=("abs_amount", "mean"),
            sum_abs=("abs_amount", "sum"),
        )
        .reset_index()
)

st.dataframe(freq, use_container_width=True)
st.bar_chart(freq.set_index("flow")["tx_cnt"], use_container_width=True)

# E) –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç—Ä–∞—Ç –≤ —Ä–∞–∑–Ω–æ–µ –≤—Ä–µ–º—è —Å—É—Ç–æ–∫
st.subheader("üïí –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç—Ä–∞—Ç –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫ (spend)")

top_tod = (
    df_spend.groupby(["tod", "mcc_code"])
            .agg(cnt=("amount", "size"), spend_sum=("abs_amount", "sum"))
            .reset_index()
            .sort_values(["tod", "spend_sum"], ascending=[True, False])
)

if "mcc_description" in df_spend.columns:
    top_tod = top_tod.merge(
        df_spend[["mcc_code", "mcc_description"]].drop_duplicates(),
        on="mcc_code",
        how="left"
    )

st.dataframe(top_tod.groupby("tod").head(10), use_container_width=True)

# F) –î–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞—Å—Ö–æ–¥–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏ –ø–æ–ª—É –∫–ª–∏–µ–Ω—Ç–æ–≤
st.subheader("üë• –†–∞—Å—Ö–æ–¥—ã –ø–æ MCC –∏ –ø–æ–ª—É (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)")

if has_gender and df_spend["gender"].notna().any():
    gcat = (
        df_spend.groupby(["gender", "mcc_code"])
                .agg(spend_sum=("abs_amount", "sum"), cnt=("amount", "size"))
                .reset_index()
                .sort_values("spend_sum", ascending=False)
    )

    if "mcc_description" in df_spend.columns:
        gcat = gcat.merge(
            df_spend[["mcc_code", "mcc_description"]].drop_duplicates(),
            on="mcc_code",
            how="left"
        )

    st.dataframe(gcat.head(30), use_container_width=True)

    top_mcc = (
        df_spend.groupby("mcc_code")["abs_amount"]
                .sum()
                .sort_values(ascending=False)
                .head(15)
                .index
                .tolist()
    )
    gcat_top = gcat[gcat["mcc_code"].isin(top_mcc)].copy()
    pivot = gcat_top.pivot_table(index="mcc_code", columns="gender", values="spend_sum", fill_value=0)
    st.bar_chart(pivot, use_container_width=True)
else:
    st.info("–ü–æ–ª (gender) –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ –ø–æ–¥–≥—Ä—É–∑–∏–ª—Å—è ‚Äî –±–ª–æ–∫ –ø—Ä–æ–ø—É—â–µ–Ω.")


# ============================================================
# G) –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–±—ã—Ç–∏–π (—Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏) ‚Äî —Ç–æ–ª—å–∫–æ Analyst
# ============================================================

st.subheader("üßæ –¢–∞–±–ª–∏—Ü–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π (—Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏)")

if not is_analyst:
    st.info("–†–æ–ª—å Viewer: –¥–æ—Å—Ç—É–ø–Ω—ã –∞–≥—Ä–µ–≥–∞—Ç—ã –∏ –≥—Ä–∞—Ñ–∏–∫–∏. –¢–∞–±–ª–∏—Ü–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ Analyst.")
else:
    cols_show = [
        "customer_id", "tr_datetime", "hour", "tod",
        "mcc_code", "mcc_description",
        "tr_type", "tr_description",
        "amount", "flow", "term_id", "gender"
    ]
    cols_show = [c for c in cols_show if c in df_f.columns]

    limit_rows = st.slider("–õ–∏–º–∏—Ç —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ", 1000, 50000, 20000, step=1000, key="table_limit_22")
    st.dataframe(df_f[cols_show].head(limit_rows), use_container_width=True)

    st.caption("‚úÖ –ó–∞–¥–∞–Ω–∏–µ 2.2: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è + –≤—ã—á–∏—Å–ª–µ–Ω–∏—è + –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã.")

    with st.expander("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤"):
        st.write({
            "rows_after_filters": int(len(df_f)),
            "unique_customers": int(df_f["customer_id"].nunique()),
            "mcc_selected": mcc_selected[:10],
            "tod_selected": tod_selected,
            "gender_filter_enabled": bool(gender_selected is not None),
            "flow_selected": flow_selected,
        })


# ============================================================
# 7) –ü–û–î–°–ö–ê–ó–ö–ò –î–õ–Ø –°–û–†–ï–í–ù–û–í–ê–ù–ò–Ø
# ============================================================

with st.expander("üõ† –ß—Ç–æ –º–µ–Ω—è—Ç—å –ø–æ–¥ –¥—Ä—É–≥–∏–µ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è (—à–ø–∞—Ä–≥–∞–ª–∫–∞)"):
    st.markdown(
        """
**–ú–µ–Ω—è–µ–º —á–∞—â–µ –≤—Å–µ–≥–æ:**
- `DB_PATH` ‚Äî –ø—É—Ç—å –∫ –±–∞–∑–µ  
- `EVENTS_TABLE / MCC_TABLE / TYPES_TABLE / GENDER_TABLE` ‚Äî –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü  
- `ID_COL / DT_COL / MCC_COL / TYPE_COL / AMOUNT_COL` ‚Äî –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫  
- `MAX_ROWS` ‚Äî –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –æ–±—ä—ë–º—É  
- –õ–æ–≥–∏–∫—É `flow`: —Å–µ–π—á–∞—Å –ø–æ –∑–Ω–∞–∫—É `amount`  

**–ï—Å–ª–∏ –Ω–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤/–ø–æ–ª–∞:**  
–∫–æ–¥ –Ω–µ –ø–∞–¥–∞–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ —É–±–∏—Ä–∞–µ—Ç —á–∞—Å—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π.
        """
    )